This project focuses on classifying mental healthâ€“related text using BERT (Bidirectional Encoder Representations from Transformers) for deep contextual understanding and LIME (Local Interpretable Model-agnostic Explanations) for model interpretability.
The aim is to detect patterns in mental health discussions (e.g., depression, anxiety, or stress) and explain which words influence the modelâ€™s decisions.

ðŸŽ¯ Objectives

Build a text classification model using BERT.

Apply LIME to visualize and explain predictions.

Evaluate and compare performance metrics.

Contribute to explainable AI for sensitive mental health applications.
