This project focuses on classifying mental healthâ€“related text using BERT (Bidirectional Encoder Representations from Transformers) for deep contextual understanding and LIME (Local Interpretable Model-agnostic Explanations) for model interpretability.
The aim is to detect patterns in mental health discussions (e.g., depression, anxiety, or stress) and explain which words influence the modelâ€™s decisions.

ðŸŽ¯ Objectives

Build a text classification model using BERT.

Apply LIME to visualize and explain predictions.

Evaluate and compare performance metrics.

Contribute to explainable AI for sensitive mental health applications.
heres the dashboard which explain you in sentence which word comes under which class
<img width="892" height="267" alt="image" src="https://github.com/user-attachments/assets/01655429-0595-4b2f-ad69-9b96d672df3f" />
heres the confusion matrix
<img width="602" height="520" alt="image" src="https://github.com/user-attachments/assets/cf443592-8554-4829-b596-fc96bec2df28" />
